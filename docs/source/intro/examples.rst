.. _examples:

Examples
========

.. contents:: Table of Contents
   :depth: 1
   :local:
   :backlinks: none

.. raw:: html

   <hr>

Learning in a Gym environment (one agent, one environment)
----------------------------------------------------------

This example performs the training of one agent in an OpenAI Gym environment

.. image:: ../_static/imgs/example_gym.png
      :width: 100%
      :align: center
      :alt: OpenAI Gym environments

.. raw:: html

   <br>

The following components or practices are exemplified (highlighted):

    - Load and wrap an OpenAI Gym environment: **Pendulum (DDPG)**
    - Instantiate models using the model instantiation utility: **CartPole (DQN)**
    - Create a tabular model (:math:`\epsilon`-greedy policy): **Taxi (SARSA)**, **FrozenLake (Q-Learning)**
    - Load a checkpoint during evaluation: **Pendulum (DDPG)**, **CartPole (DQN)**, **Taxi (SARSA)**, **FrozenLake (Q-Learning)**

.. tabs::
            
    .. tab:: Pendulum (DDPG)

        .. tabs::
            
            .. tab:: Training

                View the raw code: `gym_pendulum_ddpg.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_pendulum_ddpg.py>`_

                .. literalinclude:: ../examples/gym/gym_pendulum_ddpg.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 1, 13, 49-55, 99

            .. tab:: Evaluation
                
                View the raw code: `gym_pendulum_ddpg_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_pendulum_ddpg_eval.py>`_

                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym/gym_pendulum_ddpg_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 45, 48, 73

    .. tab:: CartPole (DQN)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code: `gym_cartpole_dqn.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_cartpole_dqn.py>`_

                .. literalinclude:: ../examples/gym/gym_cartpole_dqn.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 4, 31-50, 69
        
            .. tab:: Evaluation
                
                View the raw code: `gym_cartpole_dqn_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_cartpole_dqn_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym/gym_cartpole_dqn_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 26-35, 38, 64
    
    .. tab:: Taxi (SARSA)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code: `gym_taxi_sarsa.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_taxi_sarsa.py>`_

                .. literalinclude:: ../examples/gym/gym_taxi_sarsa.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 6, 13-28
        
            .. tab:: Evaluation
                
                View the raw code: `gym_taxi_sarsa_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_taxi_sarsa_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym/gym_taxi_sarsa_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 47-48, 51, 76
    
    .. tab:: FrozenLake (Q-learning)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code: `gym_frozen_lake_q_learning.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_frozen_lake_q_learning.py>`_

                .. literalinclude:: ../examples/gym/gym_frozen_lake_q_learning.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 6, 13-28
        
            .. tab:: Evaluation
                
                View the raw code: `gym_frozen_lake_q_learning_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym/gym_frozen_lake_q_learning_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym/gym_frozen_lake_q_learning_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 47-48, 51, 76

.. raw:: html

   <hr>

Learning in a DeepMind environment (one agent, one environment)
---------------------------------------------------------------

This example performs the training of one agent in an DeepMind environment

.. image:: ../_static/imgs/example_deepmind.png
      :width: 100%
      :align: center
      :alt: DeepMind environments

.. raw:: html

   <br>

The following components or practices are exemplified (highlighted):

    - Load and wrap a DeepMind environment: **cartpole (DDPG)**
    - Map the observation/state space (flat tensor) to the original environment space to be used by the model: **reach_site_vision (SAC)**

.. tabs::
            
    .. tab:: suite:cartpole (DDPG)

        .. tabs::
            
            .. tab:: Training

                View the raw code: `dm_suite_cartpole_swingup_ddpg.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/deepmind/dm_suite_cartpole_swingup_ddpg.py>`_

                .. literalinclude:: ../examples/deepmind/dm_suite_cartpole_swingup_ddpg.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 1, 13, 48-49, 93
    
    .. tab:: manipulation:reach_site_vision (SAC)

        .. tabs::
            
            .. tab:: Training

                View the raw code: `dm_manipulation_stack_sac.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/deepmind/dm_manipulation_stack_sac.py>`_

                .. literalinclude:: ../examples/deepmind/dm_manipulation_stack_sac.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 67, 80, 83-84, 111, 114, 117-118

.. raw:: html

   <hr>

Learning in an Isaac Gym environment (one agent, multiple environments)
-----------------------------------------------------------------------

These examples perform the training of an agent in all Isaac Gym environments. The scripts try to load the environment from preview 3, but if they fail, they will try to load the environment from preview 2

.. image:: ../_static/imgs/example_isaacgym.png
      :width: 100%
      :align: center
      :alt: Isaac Gym environments

.. raw:: html

   <br>

The following components or practices are exemplified (highlighted):

    - Load and wrap an Isaac Gym environment: **AllegroHand**, **Ant**, **Anymal**
    - Set a random seed for reproducibility: **AnymalTerrain**, **BallBalance**, **Cartpole**
    - Set a learning rate scheduler: **FrankaCabinet**, **Humanoid**, **Ingenuity**
    - Define a reward shaping function: **Quadcopter**, **ShadowHand**, **Trifinger**
    - Load a checkpoint during evaluation: **Cartpole**

The PPO agent configuration is mapped, as far as possible, from the rl_games' A2C-PPO configuration for `Isaac Gym preview 3 environments <https://github.com/NVIDIA-Omniverse/IsaacGymEnvs/tree/main/isaacgymenvs/cfg/train>`_. The following list shows the mapping between the two configurations

.. code-block:: bash

    rollouts = horizon_length
    learning_epochs = mini_epochs
    mini_batches = horizon_length * num_actors / minibatch_size
    discount_factor = gamma
    lambda = tau
    learning_rate = learning_rate
    learning_rate_scheduler = skrl.resources.schedulers.torch.KLAdaptiveRL
    learning_rate_scheduler_kwargs = {"kl_threshold": kl_threshold}
    random_timesteps = 0
    learning_starts = 0
    grad_norm_clip = grad_norm
    ratio_clip = e_clip
    value_clip = e_clip
    clip_predicted_values = clip_value
    entropy_loss_scale = entropy_coef
    value_loss_scale = 0.5 * critic_coef
    kl_threshold = 0
    rewards_shaper = lambda rewards, timestep, timesteps: rewards * scale_value

.. note::

    Isaac Gym environments implement a functionality to get their configuration from the command line. Because of this feature, setting the :literal:`headless` option from the trainer configuration will not work.  In this case, it is necessary to invoke the scripts as follows: :literal:`python script.py headless=True` for Isaac Gym environments (preview 3) or :literal:`python script.py --headless` for Isaac Gym environments (preview 2)

.. tabs::
            
    .. tab:: Isaac Gym environments (training)

        .. tabs::
            
            .. tab:: AllegroHand
                
                View the raw code: `ppo_allegro_hand.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_allegro_hand.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_allegro_hand.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 13-14, 62-67

            .. tab:: Ant
                
                View the raw code: `ppo_ant.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_ant.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_ant.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 13-14, 62-67

            .. tab:: Anymal
                
                View the raw code: `ppo_anymal.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_anymal.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_anymal.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 13-14, 62-67

            .. tab:: AnymalTerrain
                
                View the raw code: `ppo_anymal_terrain.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_anymal_terrain.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_anymal_terrain.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 15, 19

            .. tab:: BallBalance
                
                View the raw code: `ppo_ball_balance.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_ball_balance.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_ball_balance.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 15, 19

            .. tab:: Cartpole
                
                View the raw code: `ppo_cartpole.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_cartpole.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_cartpole.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 15, 19

            .. tab:: FrankaCabinet
                
                View the raw code: `ppo_franka_cabinet.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_franka_cabinet.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_franka_cabinet.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 11, 97-98

            .. tab:: Humanoid
                
                View the raw code: `ppo_humanoid.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_humanoid.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_humanoid.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 11, 97-98

            .. tab:: Ingenuity
                
                View the raw code: `ppo_ingenuity.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_ingenuity.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_ingenuity.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 11, 97-98

            .. tab:: Quadcopter
                
                View the raw code: `ppo_quadcopter.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_quadcopter.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_quadcopter.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 108

            .. tab:: ShadowHand
                
                View the raw code: `ppo_shadow_hand.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_shadow_hand.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_shadow_hand.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 112

            .. tab:: Trifinger
                
                View the raw code: `ppo_trifinger.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym3/ppo_trifinger.py>`_

                .. literalinclude:: ../examples/isaacgym3/ppo_trifinger.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 112

    .. tab:: Isaac Gym environments (evaluation)

        .. tabs::
            
            .. tab:: Cartpole
                
                View the raw code: `isaacgym_cartpole_ppo_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_cartpole_ppo_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_cartpole_ppo_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 49, 52, 76

.. raw:: html

   <hr>

Learning by scopes in an Isaac Gym environment (multiple agents and environments)
---------------------------------------------------------------------------------

This example performs the training of 3 agents by scopes in Isaac Gym's Cartpole environment in the same run. It tries to load the environment from preview 3, but if it fails, it will try to load the environment from preview 2

.. image:: ../_static/imgs/example_parallel.jpg
      :width: 100%
      :align: center
      :alt: Simultaneous training

.. raw:: html

   <br>

Two versions are presented:

    - Simultaneous (sequential) training of agents **sharing the same memory** and whose scopes are automatically selected as equally as possible
    - Simultaneous (sequential and parallel) training and evaluation of agents **with local memory** (no memory sharing) and whose scopes are manually specified and differ from each other

The following components or practices are exemplified (highlighted):

    - Create a shared memory: **Shared memory**
    - Learning by scopes (automatically defined): **Shared memory**
    - Create non-shared memories: **No shared memory**
    - Learning by scopes (manually defined): **No shared memory**
    - Load a checkpoint during evaluation: **Shared memory**, **No shared memory**

.. note::

    Isaac Gym environments implement a functionality to get their configuration from the command line. Because of this feature, setting the :literal:`headless` option from the trainer configuration will not work. In this case, it is necessary to invoke the scripts as follows: :literal:`python script.py headless=True` for Isaac Gym environments (preview 3) or :literal:`python script.py --headless` for Isaac Gym environments (preview 2)
    
.. tabs::
            
    .. tab:: Shared memory

        .. tabs::
            
            .. tab:: Sequential training
                
                View the raw code: `isaacgym_sequential_shared_memory.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_sequential_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 81, 152, 159, 166, 177-178

            .. tab:: Sequential evaluation
                
                View the raw code: `isaacgym_sequential_shared_memory_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_shared_memory_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_sequential_shared_memory_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 64, 67, 70, 73-75, 129

    .. tab:: No shared memory

        .. tabs::
            
            .. tab:: Sequential training
                
                View the raw code: `isaacgym_sequential_no_shared_memory.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_no_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_sequential_no_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 81-83, 154, 161, 168, 179-180

            .. tab:: Parallel training
                
                View the raw code: `isaacgym_parallel_no_shared_memory.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_parallel_no_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_parallel_no_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 14, 67, 179-182

            .. tab:: Sequential eval...
                
                View the raw code: `isaacgym_sequential_no_shared_memory_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_no_shared_memory_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_sequential_no_shared_memory_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 64, 67, 70, 73-75, 129

            .. tab:: Parallel eval...
                
                View the raw code: `isaacgym_parallel_no_shared_memory_eval.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_parallel_no_shared_memory_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_parallel_no_shared_memory_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 85, 88, 91, 94-96, 150

.. raw:: html

   <hr>

Learning in the Isaac Sim's (2021.2.1) JetBot environment (one agent, one environment)
--------------------------------------------------------------------------------------

This example performs the training of an agent in Isaac Sim's JetBot environment. The following components or practices are exemplified (highlighted):

    - Define and instantiate Convolutional Neural Networks (CNN) to learn from 128 X 128 RGB images

Use the steps described below (for a local workstation or a remote container) to setup and launch the experiment

.. tabs::

    .. tab:: Local workstation (setup)
        
        .. code-block:: bash

            # create a working directory and change to it
            mkdir ~/.local/share/ov/pkg/isaac_sim-2021.2.1/standalone_examples/api/omni.isaac.jetbot/skrl_example 
            cd ~/.local/share/ov/pkg/isaac_sim-2021.2.1/standalone_examples/api/omni.isaac.jetbot/skrl_example 

            # install the skrl library in editable mode from the working directory
            ~/.local/share/ov/pkg/isaac_sim-2021.2.1/python.sh -m pip install -e git+https://github.com/Toni-SM/skrl.git#egg=skrl

            # download the sample code from GitHub
            wget https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot.py

            # copy the Isaac Sim sample environment (JetBotEnv) to the working directory
            cp ../stable_baselines_example/env.py .

            # run the experiment
            ~/.local/share/ov/pkg/isaac_sim-2021.2.1/python.sh isaacsim_jetbot.py

    .. tab:: Remote container (setup)

        .. code-block:: bash

            # create a working directory and change to it
            mkdir /isaac-sim/standalone_examples/api/omni.isaac.jetbot/skrl_example 
            cd /isaac-sim/standalone_examples/api/omni.isaac.jetbot/skrl_example

            # install the skrl library in editable mode from the working directory
            /isaac-sim/kit/python/bin/python3 -m pip install -e git+https://github.com/Toni-SM/skrl.git#egg=skrl

            # download the sample code from GitHub
            wget https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot.py

            # copy the Isaac Sim sample environment (JetBotEnv) to the working directory
            cp ../stable_baselines_example/env.py .

            # run the experiment
            /isaac-sim/python.sh isaacsim_jetbot.py

.. tabs::
            
    .. tab:: Isaac Sim (JetBotEnv)
        
        View the raw code: `isaacsim_jetbot_ppo.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot_ppo.py>`_

        .. literalinclude:: ../examples/isaacsim_jetbot_ppo.py
            :language: python
            :linenos:
            :emphasize-lines: 19-47, 49-73

.. _library_utilities:

Library utilities (skrl.utils module)
-------------------------------------

This example shows how to use the library utilities to carry out the post-processing of files and data generated by the experiments

.. tabs::
            
    .. tab:: Tensorboard files
        
        .. image:: ../_static/imgs/utils_tensorboard_file_iterator.svg
            :width: 100%
            :alt: Tensorboard file iterator
        
        .. raw:: html

            <br>
            <br>

        Example of a figure, generated by the code, showing the total reward (left) and the mean and standard deviation (right) of all experiments located in the runs folder
        
        View the raw code: `tensorboard_file_iterator.py <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/utils/tensorboard_file_iterator.py>`_

        **Note:** The code will load all the Tensorboard files of the experiments located in the :literal:`runs` folder. It is necessary to adjust the iterator's parameters for other paths

        .. literalinclude:: ../examples/utils/tensorboard_file_iterator.py
            :language: python
            :linenos:
            :emphasize-lines: 4, 11-13
