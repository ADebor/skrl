.. _examples:

Examples
========

.. contents:: Table of Contents
   :depth: 1
   :local:
   :backlinks: none

.. raw:: html

   <hr>

Learning in a Gym environment (one agent, one environment)
----------------------------------------------------------

This example performs the training of one agent in an OpenAI Gym environment. The following components or practices are exemplified (highlighted):

    - Load and wrap an OpenAI Gym environment: **Pendulum (DDPG)**
    - Instantiate models using the model instantiation utility: **CartPole (DQN)**
    - Create a tabular model (:math:`\epsilon`-greedy policy): **Taxi (SARSA)**, **FrozenLake (Q-Learning)**
    - Load a checkpoint during evaluation: **Pendulum (DDPG)**, **CartPole (DQN)**, **Taxi (SARSA)**, **FrozenLake (Q-Learning)**

.. tabs::
            
    .. tab:: Pendulum (DDPG)

        .. tabs::
            
            .. tab:: Training

                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_pendulum_ddpg.py>`_

                .. literalinclude:: ../examples/gym_pendulum_ddpg.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 13, 49-55, 99

            .. tab:: Evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_pendulum_ddpg_eval.py>`_

                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym_pendulum_ddpg_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 45-48, 51, 76

    .. tab:: CartPole (DQN)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_cartpole_dqn.py>`_

                .. literalinclude:: ../examples/gym_cartpole_dqn.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 4, 31-50, 69
        
            .. tab:: Evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_cartpole_dqn_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym_cartpole_dqn_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 26-36, 39, 65
    
    .. tab:: Taxi (SARSA)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_taxi_sarsa.py>`_

                .. literalinclude:: ../examples/gym_taxi_sarsa.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 6, 13-28
        
            .. tab:: Evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_taxi_sarsa_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym_taxi_sarsa_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 47-48, 51, 76
    
    .. tab:: FrozenLake (Q-learning)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_frozen_lake_q_learning.py>`_

                .. literalinclude:: ../examples/gym_frozen_lake_q_learning.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 6, 13-28
        
            .. tab:: Evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/gym_frozen_lake_q_learning_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/gym_frozen_lake_q_learning_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 47-48, 51, 76

.. raw:: html

   <hr>

Learning in an Isaac Gym environment (one agent, multiple environments)
-----------------------------------------------------------------------

This example performs the training of an agent in Isaac Gym's Cartpole environment. It tries to load the environment from preview 3, but if it fails, it will try to load the environment from preview 2. The following components or practices are exemplified (highlighted):

    - Load and wrap an Isaac Gym environment
    - Load a checkpoint during evaluation

.. note::

    Isaac Gym environments implement a functionality to get their configuration from the command line. Because of this feature, setting the :literal:`headless` option from the trainer configuration will not work.  In this case, it is necessary to invoke the scripts as follows: :literal:`python script.py headless=True` for Isaac Gym environments (preview 3) or :literal:`python script.py --headless` for Isaac Gym environments (preview 2)

.. tabs::
            
    .. tab:: Isaac Gym (one agent)

        .. tabs::
            
            .. tab:: Training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_cartpole_ppo.py>`_

                .. literalinclude:: ../examples/isaacgym_cartpole_ppo.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 12-13, 53-58, 102

            .. tab:: Evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_cartpole_ppo_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_cartpole_ppo_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 49-50, 53, 77

.. raw:: html

   <hr>

Learning by scopes in an Isaac Gym environment (multiple agents and environments)
---------------------------------------------------------------------------------

This example performs the training of 3 agents by scopes in Isaac Gym's Cartpole environment in the same run. It tries to load the environment from preview 3, but if it fails, it will try to load the environment from preview 2

.. image:: ../_static/imgs/example_parallel.jpg
      :width: 100%
      :align: center
      :alt: Simultaneous training

Two versions are presented:

    - Simultaneous (sequential) training of agents **sharing the same memory** and whose scopes are automatically selected as equally as possible
    - Simultaneous (sequential and parallel) training of agents **with individual memory** (no memory sharing) and whose scopes are manually specified and differ from each other

The following components or practices are exemplified (highlighted):

    - Create a shared memory: **Shared memory**
    - Learning by scopes (automatically defined): **Shared memory**
    - Create non-shared memories: **No shared memory**
    - Learning by scopes (manually defined): **No shared memory**
    - Load a checkpoint during evaluation: **Shared memory**, **No shared memory**

.. note::

    Isaac Gym environments implement a functionality to get their configuration from the command line. Because of this feature, setting the :literal:`headless` option from the trainer configuration will not work.  In this case, it is necessary to invoke the scripts as follows: :literal:`python script.py headless=True` for Isaac Gym environments (preview 3) or :literal:`python script.py --headless` for Isaac Gym environments (preview 2)
    
.. tabs::
            
    .. tab:: Shared memory

        .. tabs::
            
            .. tab:: Sequential training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_sequential_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 81, 152, 159, 166, 177-178

            .. tab:: Sequential evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_shared_memory_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_sequential_shared_memory_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 64-67, 70-75, 78-82, 85-87, 141

    .. tab:: No shared memory

        .. tabs::
            
            .. tab:: Sequential training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_no_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_sequential_no_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 81-83, 154, 161, 168, 179-180

            .. tab:: Parallel training
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_parallel_no_shared_memory.py>`_

                .. literalinclude:: ../examples/isaacgym_parallel_no_shared_memory.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 14, 67, 179-182

            .. tab:: Sequential evaluation
                
                View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacgym_sequential_no_shared_memory_eval.py>`_
                
                **Note:** It is necessary to adjust the checkpoint path according to the directories generated by the new experiments

                .. literalinclude:: ../examples/isaacgym_sequential_no_shared_memory_eval.py
                    :language: python
                    :linenos:
                    :emphasize-lines: 64-67, 70-75, 78-82, 85-87, 141

.. raw:: html

   <hr>

Learning in the Isaac Sim's (2021.2.1) JetBot environment (one agent, one environment)
--------------------------------------------------------------------------------------

This example performs the training of an agent in Isaac Sim's JetBot environment. The following components or practices are exemplified (highlighted):

    - Define and instantiate Convolutional Neural Networks (CNN) to learn from 128 X 128 RGB images

Use the steps described below (for a local workstation or a remote container) to setup and launch the experiment

.. tabs::

    .. tab:: Local workstation (setup)
        
        .. code-block:: bash

            # create a working directory and change to it
            mkdir ~/.local/share/ov/pkg/isaac_sim-2021.2.1/standalone_examples/api/omni.isaac.jetbot/skrl_example 
            cd ~/.local/share/ov/pkg/isaac_sim-2021.2.1/standalone_examples/api/omni.isaac.jetbot/skrl_example 

            # install the skrl library in editable mode from the working directory
            ~/.local/share/ov/pkg/isaac_sim-2021.2.1/python.sh -m pip install -e git+https://github.com/Toni-SM/skrl.git#egg=skrl

            # download the sample code from GitHub
            wget https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot.py

            # copy the Isaac Sim sample environment (JetBotEnv) to the working directory
            cp ../stable_baselines_example/env.py .

            # run the experiment
            ~/.local/share/ov/pkg/isaac_sim-2021.2.1/python.sh isaacsim_jetbot.py

    .. tab:: Remote container (setup)

        .. code-block:: bash

            # create a working directory and change to it
            mkdir /isaac-sim/standalone_examples/api/omni.isaac.jetbot/skrl_example 
            cd /isaac-sim/standalone_examples/api/omni.isaac.jetbot/skrl_example

            # install the skrl library in editable mode from the working directory
            /isaac-sim/kit/python/bin/python3 -m pip install -e git+https://github.com/Toni-SM/skrl.git#egg=skrl

            # download the sample code from GitHub
            wget https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot.py

            # copy the Isaac Sim sample environment (JetBotEnv) to the working directory
            cp ../stable_baselines_example/env.py .

            # run the experiment
            /isaac-sim/python.sh isaacsim_jetbot.py

.. tabs::
            
    .. tab:: Isaac Sim (JetBotEnv)
        
        View the raw code `here <https://raw.githubusercontent.com/Toni-SM/skrl/main/docs/source/examples/isaacsim_jetbot_ppo.py>`_

        .. literalinclude:: ../examples/isaacsim_jetbot_ppo.py
            :language: python
            :linenos:
            :emphasize-lines: 19-47, 49-73